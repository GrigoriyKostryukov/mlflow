{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Examples for scikit-learn Autologging\n",
        "\n",
        "| File                                           | Description                                         |\n",
        "| :--------------------------------------------- | :-------------------------------------------------- |\n",
        "| [linear_regression.py](https://www.google.com/url?sa=i&url=https%3A%2F%2Fru.pinterest.com%2Fpin%2F595671488248154464%2F&psig=AOvVaw239wq5rotNeaT5CphAL-vH&ust=1732901616336000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCMj_4d_H_4kDFQAAAAAdAAAAABAJ) | Train a [LinearRegression][lr] model                |\n",
        "| [pipeline.py](https://www.google.com/url?sa=i&url=https%3A%2F%2Fru.pinterest.com%2Fpin%2F595671488248154464%2F&psig=AOvVaw239wq5rotNeaT5CphAL-vH&ust=1732901616336000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCMj_4d_H_4kDFQAAAAAdAAAAABAJ)                   | Train a [Pipeline][pipe] model                      |\n",
        "| [grid_search_cv.py](https://www.google.com/url?sa=i&url=https%3A%2F%2Fru.pinterest.com%2Fpin%2F595671488248154464%2F&psig=AOvVaw239wq5rotNeaT5CphAL-vH&ust=1732901616336000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCMj_4d_H_4kDFQAAAAAdAAAAABAJ)       | Perform a parameter search using [GridSearchCV][gs] |\n",
        "\n",
        "[lr]: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "[pipe]: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "[gs]: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
      ],
      "metadata": {
        "id": "Xy6lkRzXi3h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxXzwF-ijZ0x",
        "outputId": "904e87cb-5ab3-46af-897f-593729749e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.18.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.0.3)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow)\n",
            "  Downloading databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (4.25.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.1/575.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 databricks-sdk-0.38.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.18.0 mlflow-skinny-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient"
      ],
      "metadata": {
        "id": "T-8c1uW-i25g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_artifacts(run_id, path=None):\n",
        "    \"\"\"\n",
        "    Recursively yield all artifact paths for a specified MLflow run.\n",
        "\n",
        "    Args:\n",
        "        run_id (str): The unique identifier of the MLflow run.\n",
        "        path (str, optional): A specific path within the artifact repository.\n",
        "            If not provided, the root directory is used.\n",
        "\n",
        "    Yields:\n",
        "        str: Paths to the artifacts stored in the run's artifact repository.\n",
        "\n",
        "    This function uses the MLflow client to traverse the artifact directory structure\n",
        "    and yields paths to all individual artifacts. If an artifact is a directory,\n",
        "    the function recursively explores its contents.\n",
        "    \"\"\"\n",
        "    client = MlflowClient()\n",
        "    for item in client.list_artifacts(run_id, path):\n",
        "        if item.is_dir:\n",
        "            yield from yield_artifacts(run_id, item.path)\n",
        "        else:\n",
        "            yield item.path\n",
        "\n",
        "\n",
        "def fetch_logged_data(run_id):\n",
        "    \"\"\"\n",
        "    Fetch logged parameters, metrics, tags, and artifact paths from an MLflow run.\n",
        "\n",
        "    Args:\n",
        "        run_id (str): The unique identifier of the MLflow run.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the following keys:\n",
        "            - \"params\": A dictionary of parameters logged to the run.\n",
        "            - \"metrics\": A dictionary of metrics logged to the run.\n",
        "            - \"tags\": A dictionary of user-defined tags (excluding system tags).\n",
        "            - \"artifacts\": A list of paths to artifacts stored in the run's artifact repository.\n",
        "\n",
        "    This function uses the MLflow client to retrieve logged data from the specified run.\n",
        "    System tags (e.g., tags starting with \"mlflow.\") are excluded from the returned tags.\n",
        "    \"\"\"\n",
        "    client = MlflowClient()\n",
        "    data = client.get_run(run_id).data\n",
        "    # Exclude system tags: https://www.mlflow.org/docs/latest/tracking.html#system-tags\n",
        "    tags = {k: v for k, v in data.tags.items() if not k.startswith(\"mlflow.\")}\n",
        "    artifacts = list(yield_artifacts(run_id))\n",
        "    return {\n",
        "        \"params\": data.params,\n",
        "        \"metrics\": data.metrics,\n",
        "        \"tags\": tags,\n",
        "        \"artifacts\": artifacts,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Gezeq5Q0jIJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-BFnrGhisBI",
        "outputId": "349c8655-3709-4ef5-d180-894535cc3a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/28 17:31:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '30cab0dbed3f4ebc9a0dc0acc94a0ad1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged data and model in run 30cab0dbed3f4ebc9a0dc0acc94a0ad1\n",
            "\n",
            "---------- logged params ----------\n",
            "{'copy_X': 'True',\n",
            " 'fit_intercept': 'True',\n",
            " 'n_jobs': 'None',\n",
            " 'positive': 'False'}\n",
            "\n",
            "---------- logged metrics ----------\n",
            "{'training_mean_absolute_error': 2.220446049250313e-16,\n",
            " 'training_mean_squared_error': 1.9721522630525295e-31,\n",
            " 'training_r2_score': 1.0,\n",
            " 'training_root_mean_squared_error': 4.440892098500626e-16,\n",
            " 'training_score': 1.0}\n",
            "\n",
            "---------- logged tags ----------\n",
            "{'estimator_class': 'sklearn.linear_model._base.LinearRegression',\n",
            " 'estimator_name': 'LinearRegression'}\n",
            "\n",
            "---------- logged artifacts ----------\n",
            "['estimator.html',\n",
            " 'model/MLmodel',\n",
            " 'model/conda.yaml',\n",
            " 'model/model.pkl',\n",
            " 'model/python_env.yaml',\n",
            " 'model/requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from pprint import pprint\n",
        "\n",
        "# Enable automatic logging of parameters, metrics, and models for scikit-learn\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Prepare training data\n",
        "# X is a 2D array representing features, y is the target variable calculated using a linear equation.\n",
        "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
        "y = np.dot(X, np.array([1, 2])) + 3  # Linear function: y = 1*x1 + 2*x2 + 3\n",
        "\n",
        "# Train a linear regression model\n",
        "# The LinearRegression model from scikit-learn is trained on the data.\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Retrieve the MLflow run ID of the last active run\n",
        "# This ID is used to query data logged during the run.\n",
        "run_id = mlflow.last_active_run().info.run_id\n",
        "print(f\"Logged data and model in run {run_id}\")\n",
        "\n",
        "# Display logged data\n",
        "# Use the `fetch_logged_data` function to retrieve and display:\n",
        "# - Parameters: Model hyperparameters\n",
        "# - Metrics: Training metrics (e.g., R² score)\n",
        "# - Tags: Metadata about the run\n",
        "# - Artifacts: Files/logs/models stored in the artifact repository\n",
        "for key, data in fetch_logged_data(run_id).items():\n",
        "    print(f\"\\n---------- logged {key} ----------\")\n",
        "    pprint(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "\n",
        "# Enable automatic logging of parameters, metrics, and models for scikit-learn\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Load the Iris dataset\n",
        "# `iris.data` contains feature data, and `iris.target` contains labels (classifications).\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Define parameters for GridSearchCV\n",
        "# `parameters` specifies the hyperparameter grid for tuning.\n",
        "parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 10]}\n",
        "\n",
        "# Create an SVM model and set up a grid search\n",
        "svc = svm.SVC()  # Support Vector Classifier\n",
        "clf = GridSearchCV(svc, parameters)  # Grid search over `kernel` and `C`\n",
        "\n",
        "# Fit the grid search to the data\n",
        "# This trains multiple models with different parameter combinations to find the best one.\n",
        "clf.fit(iris.data, iris.target)\n",
        "\n",
        "# Retrieve the MLflow run ID of the parent run (created by `autolog`)\n",
        "run_id = mlflow.last_active_run().info.run_id\n",
        "\n",
        "# Show data logged in the parent run\n",
        "# The parent run contains information about the entire grid search process.\n",
        "print(\"========== parent run ==========\")\n",
        "for key, data in fetch_logged_data(run_id).items():\n",
        "    print(f\"\\n---------- logged {key} ----------\")\n",
        "    pprint(data)\n",
        "\n",
        "# Show data logged in the child runs\n",
        "# Each child run corresponds to a specific parameter combination in GridSearchCV.\n",
        "filter_child_runs = f\"tags.mlflow.parentRunId = '{run_id}'\"\n",
        "runs = mlflow.search_runs(filter_string=filter_child_runs)\n",
        "\n",
        "# Extract specific columns for display:\n",
        "# - `params.kernel` and `params.C`: The hyperparameters for each child run.\n",
        "# - `metrics.mean_test_score`: The average test score for each parameter combination.\n",
        "param_cols = [f\"params.{p}\" for p in parameters.keys()]\n",
        "metric_cols = [\"metrics.mean_test_score\"]\n",
        "\n",
        "print(\"\\n========== child runs ==========\\n\")\n",
        "pd.set_option(\"display.max_columns\", None)  # Prevent truncating columns in the output\n",
        "print(runs[[\"run_id\", *param_cols, *metric_cols]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F7OnddyjAP_",
        "outputId": "49ffd526-0f18-45e3-f619-81577ef9f38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/28 17:32:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e685c79ffb5f43b99211606b38d93be2', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
            "2024/11/28 17:32:16 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== parent run ==========\n",
            "\n",
            "---------- logged params ----------\n",
            "{'best_C': '1',\n",
            " 'best_kernel': 'linear',\n",
            " 'cv': 'None',\n",
            " 'error_score': 'nan',\n",
            " 'estimator': 'SVC()',\n",
            " 'n_jobs': 'None',\n",
            " 'param_grid': \"{'kernel': ('linear', 'rbf'), 'C': [1, 10]}\",\n",
            " 'pre_dispatch': '2*n_jobs',\n",
            " 'refit': 'True',\n",
            " 'return_train_score': 'False',\n",
            " 'scoring': 'None',\n",
            " 'verbose': '0'}\n",
            "\n",
            "---------- logged metrics ----------\n",
            "{'best_cv_score': 0.9800000000000001,\n",
            " 'training_accuracy_score': 0.9933333333333333,\n",
            " 'training_f1_score': 0.9933326665999933,\n",
            " 'training_precision_score': 0.9934640522875816,\n",
            " 'training_recall_score': 0.9933333333333333,\n",
            " 'training_score': 0.9933333333333333}\n",
            "\n",
            "---------- logged tags ----------\n",
            "{'estimator_class': 'sklearn.model_selection._search.GridSearchCV',\n",
            " 'estimator_name': 'GridSearchCV'}\n",
            "\n",
            "---------- logged artifacts ----------\n",
            "['best_estimator/MLmodel',\n",
            " 'best_estimator/conda.yaml',\n",
            " 'best_estimator/model.pkl',\n",
            " 'best_estimator/python_env.yaml',\n",
            " 'best_estimator/requirements.txt',\n",
            " 'cv_results.csv',\n",
            " 'estimator.html',\n",
            " 'model/MLmodel',\n",
            " 'model/conda.yaml',\n",
            " 'model/model.pkl',\n",
            " 'model/python_env.yaml',\n",
            " 'model/requirements.txt',\n",
            " 'training_confusion_matrix.png']\n",
            "\n",
            "========== child runs ==========\n",
            "\n",
            "                             run_id params.kernel params.C  \\\n",
            "0  2e9b440c153945368a9a56efd23883de        linear        1   \n",
            "1  5d7fe25a882d461da302e8f93a541955           rbf       10   \n",
            "2  7e61fd8e71f446b99e12604fc683c991           rbf        1   \n",
            "3  e226092428fa49ae8e63bd7835f786d5        linear       10   \n",
            "\n",
            "   metrics.mean_test_score  \n",
            "0                 0.980000  \n",
            "1                 0.980000  \n",
            "2                 0.966667  \n",
            "3                 0.973333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from pprint import pprint\n",
        "\n",
        "# Enable automatic logging for scikit-learn models\n",
        "# This feature automatically tracks model parameters, metrics, and artifacts (e.g., trained model files) in MLflow.\n",
        "mlflow.sklearn.autolog()\n",
        "\n",
        "# Prepare training data\n",
        "# X is a matrix of features, and y is the target variable.\n",
        "# The target variable is calculated as a linear combination of the features plus an intercept.\n",
        "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
        "y = np.dot(X, np.array([1, 2])) + 3  # Linear equation: y = 1*x1 + 2*x2 + 3\n",
        "\n",
        "# Create and train a pipeline model\n",
        "# The pipeline consists of:\n",
        "# 1. `StandardScaler`: Standardizes the features to have zero mean and unit variance.\n",
        "# 2. `LinearRegression`: Fits a linear model to the standardized features and target.\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LinearRegression())])\n",
        "pipe.fit(X, y)\n",
        "\n",
        "# Retrieve the MLflow run ID of the last active run\n",
        "# This ID uniquely identifies the MLflow run and is used to fetch logged data.\n",
        "run_id = mlflow.last_active_run().info.run_id\n",
        "print(f\"Logged data and model in run: {run_id}\")\n",
        "\n",
        "# Fetch and display logged data\n",
        "# Use the `fetch_logged_data` function to retrieve:\n",
        "# - Parameters: Hyperparameters of the pipeline components.\n",
        "# - Metrics: Model evaluation metrics (e.g., R² score).\n",
        "# - Tags: Metadata about the run (e.g., library versions).\n",
        "# - Artifacts: Files such as the serialized model or other outputs.\n",
        "for key, data in fetch_logged_data(run_id).items():\n",
        "    print(f\"\\n---------- logged {key} ----------\")\n",
        "    pprint(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-CDSoMdjMsg",
        "outputId": "a1da58f8-11b3-4fce-d9ed-49e768160f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/28 17:32:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41827cf62c8c4901ae5862a18242d2d8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged data and model in run: 41827cf62c8c4901ae5862a18242d2d8\n",
            "\n",
            "---------- logged params ----------\n",
            "{'lr': 'LinearRegression()',\n",
            " 'lr__copy_X': 'True',\n",
            " 'lr__fit_intercept': 'True',\n",
            " 'lr__n_jobs': 'None',\n",
            " 'lr__positive': 'False',\n",
            " 'memory': 'None',\n",
            " 'scaler': 'StandardScaler()',\n",
            " 'scaler__copy': 'True',\n",
            " 'scaler__with_mean': 'True',\n",
            " 'scaler__with_std': 'True',\n",
            " 'steps': \"[('scaler', StandardScaler()), ('lr', LinearRegression())]\",\n",
            " 'verbose': 'False'}\n",
            "\n",
            "---------- logged metrics ----------\n",
            "{'training_mean_absolute_error': 2.220446049250313e-16,\n",
            " 'training_mean_squared_error': 1.9721522630525295e-31,\n",
            " 'training_r2_score': 1.0,\n",
            " 'training_root_mean_squared_error': 4.440892098500626e-16,\n",
            " 'training_score': 1.0}\n",
            "\n",
            "---------- logged tags ----------\n",
            "{'estimator_class': 'sklearn.pipeline.Pipeline', 'estimator_name': 'Pipeline'}\n",
            "\n",
            "---------- logged artifacts ----------\n",
            "['estimator.html',\n",
            " 'model/MLmodel',\n",
            " 'model/conda.yaml',\n",
            " 'model/model.pkl',\n",
            " 'model/python_env.yaml',\n",
            " 'model/requirements.txt']\n"
          ]
        }
      ]
    }
  ]
}